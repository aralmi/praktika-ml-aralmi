# Domain Adaptation –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

–ü—Ä–æ–µ–∫—Ç –ø–æ—Å–≤—è—â–µ–Ω —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã **domain shift** –≤ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤ –∫–∞—á–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–æ–¥–æ–≤ **Domain Adversarial Neural Networks (DANN)**. –†–∞–±–æ—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ —Ä–∞–º–∫–∞—Ö –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏ –≤ –ê–û "–†–û–¢–ï–ö –î–∏–¥–∂–∏—Ç–∞–ª –°–æ–ª—é—à–µ–Ω—Å".

## üéØ –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏

### –ü—Ä–æ–±–ª–µ–º–∞
–ú–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–∏—Ö —É—Å–ª–æ–≤–∏–π —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –≤—Ä–∞—â–µ–Ω–∏—è), –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ –Ω–∞ –¥—Ä—É–≥–∏–µ —Ä–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã. –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞ –¥–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.

### –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞
–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –º–µ—Ç–æ–¥—ã **Unsupervised Domain Adaptation** –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤ –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é —É—Å–ª–æ–≤–∏–π —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (—Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤—Ä–∞—â–µ–Ω–∏—è).

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞
- **Source Domain**: —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –≤–∏–±—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤ –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ 1500 –æ–±/–º–∏–Ω
- **Target Domain**: –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –≤–∏–±—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ 900 –æ–±/–º–∏–Ω  
- **–ö–ª–∞—Å—Å—ã**: –¥–µ—Ñ–µ–∫—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –æ–±–æ–π–º—ã (1) vs –¥–µ—Ñ–µ–∫—Ç –≤–Ω–µ—à–Ω–µ–π –æ–±–æ–π–º—ã (0)
- **–ú–µ—Ç—Ä–∏–∫–∞**: F1 Macro Score (–æ—Å–Ω–æ–≤–Ω–∞—è), AUC-ROC, Precision, Recall

## üìä –î–∞–Ω–Ω—ã–µ –∏ –∞–Ω–∞–ª–∏–∑ Domain Shift

### –î–∞—Ç–∞—Å–µ—Ç
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω **University of Paderborn Bearing Dataset** ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –≤ –æ–±–ª–∞—Å—Ç–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤:
- 4 —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤—Ä–∞—â–µ–Ω–∏—è: 1500, 900, 1800, 750 –æ–±/–º–∏–Ω
- 3 –∫–∞–Ω–∞–ª–∞ –∏–∑–º–µ—Ä–µ–Ω–∏–π: 2 —Ñ–∞–∑–æ–≤—ã—Ö —Ç–æ–∫–∞ + –≤–µ–∫—Ç–æ—Ä–Ω–∞—è —Å—É–º–º–∞ ‚àö(I‚ÇÅ¬≤ + I‚ÇÇ¬≤)
- –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: 64 –∫–ì—Ü
- –î–ª–∏–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞: –¥–æ 256,000 –æ—Ç—Å—á–µ—Ç–æ–≤

### –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –¥–æ–º–µ–Ω–æ–≤
–ü—Ä–æ–≤–µ–¥–µ–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ domain shift –º–µ–∂–¥—É —Å–∫–æ—Ä–æ—Å—Ç—è–º–∏:

**–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã:**
- –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞: p < 0.001 (–∑–Ω–∞—á–∏–º—ã–µ —Ä–∞–∑–ª–∏—á–∏—è)
- Q-Q –∞–Ω–∞–ª–∏–∑: —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ —Ö–≤–æ—Å—Ç–∞—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
- –†–∞–∑–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–Ω–∏—Ö: 0.0263, –æ—Ç–Ω–æ—à–µ–Ω–∏–µ œÉ: 0.9616

**–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:**
- **PCA**: —Å–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 2000‚Üí50 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (84.7% –¥–∏—Å–ø–µ—Ä—Å–∏–∏), —á–µ—Ç–∫–æ–µ –ª–∏–Ω–µ–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ–º–µ–Ω–æ–≤
- **t-SNE**: –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–º–µ–Ω–∞
- –ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–æ–º–µ–Ω–æ–≤: 8.234

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

### Domain Adversarial Neural Network (DANN)
–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å —Ç—Ä–µ–º—è –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏:

#### 1. CNN1D Feature Extractor
```python
- Conv1d(3‚Üí32, kernel=7) + BatchNorm + MaxPool
- Conv1d(32‚Üí64, kernel=5) + BatchNorm + MaxPool  
- Conv1d(64‚Üí128, kernel=5) + BatchNorm + MaxPool
- Conv1d(128‚Üí128, kernel=3) + BatchNorm + MaxPool
- GlobalAveragePooling ‚Üí 128 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
```

#### 2. Task Classifier
```python
- Linear(128‚Üí64) + BatchNorm + Dropout(0.2)
- Linear(64‚Üí16) + BatchNorm + Dropout(0.2)  
- Linear(16‚Üí1) + Sigmoid
```

#### 3. Domain Discriminator  
```python
- Linear(128‚Üí48) + Dropout(0.3)
- Linear(48‚Üí1) + Sigmoid
```

#### 4. Gradient Reversal Layer (GRL)
–ö–ª—é—á–µ–≤–æ–π —ç–ª–µ–º–µ–Ω—Ç DANN, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏–π adversarial –æ–±—É—á–µ–Ω–∏–µ –ø—É—Ç–µ–º –∏–Ω–≤–µ—Ä—Å–∏–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º Œª.

### –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
```python
total_loss = classification_loss + Œª * domain_loss
```
–≥–¥–µ Œª ‚Äî –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–∏–π —Å–∏–ª—É domain adaptation.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã

#### üîµ `preprocessing.ipynb` 
**–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤**

–ö–ª—é—á–µ–≤—ã–µ —ç—Ç–∞–ø—ã:
- **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ –æ–∫–Ω–∞**: —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –æ–∫–Ω–∞ 2000 –æ—Ç—Å—á–µ—Ç–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º 50%
- **–ú–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞**: —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ 3-–∫–∞–Ω–∞–ª—å–Ω–æ–≥–æ –≤—Ö–æ–¥–∞ (2 —Ç–æ–∫–∞ + –≤–µ–∫—Ç–æ—Ä–Ω–∞—è —Å—É–º–º–∞)
- **–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–æ —Ñ–∞–∑–µ**: –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–¥–≤–∏–≥–æ–≤ —á–µ—Ä–µ–∑ –∫—Ä–æ—Å—Å-–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
- **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: —Ç–æ–ª—å–∫–æ –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º source domain –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è domain shift

–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
```python
def raw_to_windows(dic):
    # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –æ–∫–Ω–∞
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π —Å—É–º–º—ã –∫–∞–∫ —Ç—Ä–µ—Ç—å–µ–≥–æ –∫–∞–Ω–∞–ª–∞
    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø–æ –∫—Ä–æ—Å—Å-–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    return X_processed, y_processed

def flat_to_cnn_shape(X_flat):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è CNN1D: (batch, channels, time)
    return X.transpose(0, 2, 1)
```

#### üî¥ `task_pytorch.ipynb` 
**–û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è DANN** (–õ–£–ß–®–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´)

–°–æ–¥–µ—Ä–∂–∏—Ç:
- –ü–æ–ª–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É DANN —Å CNN1D —ç–Ω–∫–æ–¥–µ—Ä–æ–º
- Gradient Reversal Layer —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º Œª
- –û–±—É—á–∞—é—â–∏–π —Ü–∏–∫–ª —Å –¥–≤—É–º—è —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –ø–æ—Ç–µ—Ä—å
- –°–∏—Å—Ç–µ–º—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ early stopping
- Comprehensive evaluation (–º–µ—Ç—Ä–∏–∫–∏, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –∞–Ω–∞–ª–∏–∑)

–ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
```python
class DANN(nn.Module):
    def __init__(self):
        self.feature_extractor = CNN1DEncoder()
        self.label_predictor = TaskClassifier()  
        self.domain_classifier = DomainDiscriminator()
        self.grl = GradientReversalLayer()
```

#### üü° `task_pytorch_encoder.ipynb`
**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞–º–∏**

–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä:
- CNN1D (–æ—Å–Ω–æ–≤–Ω–æ–π) ‚Äî –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
- CNN2D ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
- MLP ‚Äî baseline –±–µ–∑ —É—á–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

#### üü¢ `task_no_norm_learn.ipynb` 
**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö**

–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å/–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
- –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–∞ domain shift
- –û—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è

#### üü† `datasets.py`
**–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏**

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ University of Paderborn Dataset
# –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤
# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
```

## üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
–ü—Ä–æ–≤–µ–¥–µ–Ω–∞ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:

**–ü–∞—Ä–∞–º–µ—Ç—Ä Œª (adversarial strength):**
- –î–∏–∞–ø–∞–∑–æ–Ω: [0.05, 0.10, 0.15, 0.20, 0.25]
- **–û–ø—Ç–∏–º—É–º: Œª = 0.15** (–±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –∏ –∫–∞—á–µ—Å—Ç–≤–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
- –ü—Ä–∏ Œª < 0.1: —Å–ª–∞–±–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è
- –ü—Ä–∏ Œª > 0.2: –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ task classifier

**–§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å:**
- BCEWithLogitsLoss (–æ—Å–Ω–æ–≤–Ω–∞—è)
- **Focal Loss** (–¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö) ‚Äî —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 2-3%

**–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:**
- Dropout: 0.2 (Task Classifier), 0.3 (Domain Discriminator)
- BatchNormalization: –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
- Early Stopping: patience=6

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã:**
- –†–∞–∑–º–µ—Ä—ã kernel: [3, 5, 7] ‚Üí –æ–ø—Ç–∏–º—É–º: —É–±—ã–≤–∞—é—â–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å 7‚Üí5‚Üí3
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ CNN: 3-5 ‚Üí –æ–ø—Ç–∏–º—É–º: 4 —Å–ª–æ—è
- –†–∞–∑–º–µ—Ä—ã hidden layers: —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### Baseline —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
| –ú–æ–¥–µ–ª—å | Target F1 Macro | Target AUC | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------------|------------|-----------|
| MLP (–±–µ–∑ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏) | 52.1% | 0.573 | –°–ª—É—á–∞–π–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å |
| CNN2D | 58.3% | 0.634 | –°–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã |
| CNN1D (–±–µ–∑ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏) | 61.7% | 0.698 | –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã |
| **DANN + CNN1D** | **75.8%** | **0.847** | –ù–∞—à –ø–æ–¥—Ö–æ–¥ |

### –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã DANN

#### Target Domain (–≥–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å):
- **F1 Macro: 75.8%** üìà
- **Accuracy: 76.1%**
- **AUC-ROC: 84.7%** 
- **Precision: 78.7%** (–º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)
- **Recall: 68.7%**

#### Source Domain (trade-off):
- F1 Macro: 64.4% (—Å–Ω–∏–∂–µ–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏)
- Accuracy: 68.0%
- AUC-ROC: 87.0%

#### –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏:
- **Domain Classifier Accuracy ‚âà 63%** (–±–ª–∏–∑–∫–æ –∫ —Å–ª—É—á–∞–π–Ω–æ–º—É 50% ‚Äî –ø—Ä–∏–∑–Ω–∞–∫ —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
- –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

### –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**‚úÖ –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**
- **–ü—Ä–∏—Ä–æ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ 23.7%** (52.1% ‚Üí 75.8%) –Ω–∞ —Ü–µ–ª–µ–≤–æ–º –¥–æ–º–µ–Ω–µ
- –í—ã—Å–æ–∫–∏–π precision (78.7%) ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏
- –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ CNN1D –¥–ª—è –≤–∏–±—Ä–æ—Å–∏–≥–Ω–∞–ª–æ–≤
- Successful domain adaptation –±–µ–∑ –º–µ—Ç–æ–∫ target domain

**‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**
- –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è 90%+)
- Trade-off: —É–ª—É—á—à–µ–Ω–∏–µ target –∑–∞ —Å—á–µ—Ç source
- –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—É Œª

## üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –Ω–∞–≤—ã–∫–∏

### –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫:
- **PyTorch** ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, adversarial training
- **NumPy** ‚Äî —á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å—Å–∏–≤–æ–≤
- **Pandas** ‚Äî –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
- **Scikit-learn** ‚Äî –º–µ—Ç—Ä–∏–∫–∏, –≤–∞–ª–∏–¥–∞—Ü–∏—è, PCA, t-SNE
- **Matplotlib/Seaborn** ‚Äî –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –û—Å–≤–æ–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:
- **Domain Adaptation**: UDA, adversarial training, domain shift –∞–Ω–∞–ª–∏–∑
- **Deep Learning**: CNN –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, gradient reversal, regularization
- **Signal Processing**: –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–±—Ä–æ—Å–∏–≥–Ω–∞–ª–æ–≤, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è, —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
- **Experimental Design**: systematic hyperparameter tuning, baseline comparison
- **Industrial ML**: —Ä–∞–±–æ—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤

### –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏:
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –¥–æ–º–µ–Ω–æ–≤
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (PCA, t-SNE)
- Cross-validation –∏ proper evaluation
- Trade-off –∞–Ω–∞–ª–∏–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## üöÄ –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
```bash
pip install torch torchvision numpy pandas scikit-learn matplotlib seaborn jupyter
```

### –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø—É—Å–∫–∞:
1. **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö**: `python datasets.py`
2. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞**: –æ—Ç–∫—Ä—ã—Ç—å `preprocessing.ipynb`
3. **–û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**: –∑–∞–ø—É—Å—Ç–∏—Ç—å `task_pytorch.ipynb`
4. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã**: –∏–∑—É—á–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ notebook'–∏

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:
```
data/
‚îú‚îÄ‚îÄ bearing_data/
‚îÇ   ‚îú‚îÄ‚îÄ Normal_0/
‚îÇ   ‚îú‚îÄ‚îÄ Inner_race_1/
‚îÇ   ‚îî‚îÄ‚îÄ Outer_race_0/
‚îî‚îÄ‚îÄ processed/
    ‚îú‚îÄ‚îÄ source_domain.pkl
    ‚îî‚îÄ‚îÄ target_domain.pkl
```

## üìà –í—ã–≤–æ–¥—ã –∏ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ

### –ù–∞—É—á–Ω–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å:
- –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ DANN –¥–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
- –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ CNN1D –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–±—Ä–æ—Å–∏–≥–Ω–∞–ª–æ–≤
- –í—ã—è–≤–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è adversarial training

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å:
- –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–ª—è production-ready —Å–∏—Å—Ç–µ–º—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
- –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ –Ω–æ–≤—ã–º —É—Å–ª–æ–≤–∏—è–º —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏
- –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π —ç—Ñ—Ñ–µ–∫—Ç: —Ä–∞–Ω–Ω–µ–µ –≤—ã—è–≤–ª–µ–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤ ‚Üí —Å–Ω–∏–∂–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ —Ä–µ–º–æ–Ω—Ç

### –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —É–ª—É—á—à–µ–Ω–∏—è:
- **Multi-domain adaptation**: –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Å–∫–æ—Ä–æ—Å—Ç—è–º
- **Attention mechanisms**: —Ñ–æ–∫—É—Å –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —É—á–∞—Å—Ç–∫–∞—Ö —Å–∏–≥–Ω–∞–ª–∞  
- **Advanced architectures**: ResNet, Transformer –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
- **Semi-supervised approach**: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–µ—Ç–æ–∫ target
- **Ensemble methods**: –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ:
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Å–∏—Å—Ç–µ–º—ã predictive maintenance
- Real-time inference –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
- –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –¥—Ä—É–≥–∏–º —Ç–∏–ø–∞–º –≤—Ä–∞—â–∞—é—â–µ–≥–æ—Å—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è (—Ç—É—Ä–±–∏–Ω—ã, –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä—ã)

*–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–≤—ã–∫–∏ —Ä–∞–±–æ—Ç—ã —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–µ—à–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Ä–∞–±–æ—Ç–µ –≤ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –ò–ò.*
